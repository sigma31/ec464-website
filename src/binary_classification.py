# -*- coding: utf-8 -*-
"""Binary Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11cEKAp3f5UPXpMqHWRtgmoDjsUD0zuDM
"""

#https://www.kaggle.com/code/holdmykaggle/fire-detection-in-images/notebook
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')
zip_file_path = '/content/drive/MyDrive/FireImageData.zip'
extract_path = '/content/FireData'

import zipfile

# Create a ZipFile object
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    # Extract the contents to the specified folder
    zip_ref.extractall(extract_path)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split

sns.set_style('darkgrid')

def extract_dataset(zip_file_path, extract_path, fire_subpath, non_fire_subpath):
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

    df = pd.DataFrame(columns=['path', 'label'])

    # Loop over fire images and label them 1
    for dirname, _, filenames in os.walk(os.path.join(extract_path, fire_subpath)):
        for filename in filenames:
            df = pd.concat([df, pd.DataFrame([[os.path.join(dirname, filename), 'fire']], columns=['path', 'label'])],
                           ignore_index=True)

    # Loop over non-fire images and label them 0
    for dirname, _, filenames in os.walk(os.path.join(extract_path, non_fire_subpath)):
        for filename in filenames:
            df = pd.concat([df, pd.DataFrame([[os.path.join(dirname, filename), 'non_fire']], columns=['path', 'label'])],
                           ignore_index=True)

    # Shuffle the dataset to redistribute the labels
    df = df.sample(frac=1).reset_index(drop=True)
    return df

zip_file_path_1 = '/content/drive/MyDrive/TrainingDataset.zip'
extract_path_1 = '/content/FireTest'
df_2 = extract_dataset(zip_file_path_1, extract_path_1, 'TrainingDataset/Fire', 'TrainingDataset/NoFire')
df_2.head(10)

drive.mount('/content/drive')
zip_file_path_2 = '/content/drive/MyDrive/FireImageData.zip'
extract_path_2 = '/content/FireData'
df_1 = extract_dataset(zip_file_path_2, extract_path_2, 'fire_dataset/fire_images', 'fire_dataset/non_fire_images')
df_1.head(10)

# Check the size of the first dataset
print("Size of the first dataset (df_1):", df_1.shape[0])

# Check the size of the second dataset
print("Size of the second dataset (df_2):", df_2.shape[0])

fig = make_subplots(rows=1, cols=2, specs=[[{"type": "xy"}, {"type": "pie"}]])


fig.add_trace(go.Bar(x =df_1['label'].value_counts().index,y=df_1['label'].value_counts().to_numpy(),marker_color=['darkorange','green'],showlegend=False),row=1,col=1)

fig.add_trace(go.Pie(
     values=df_1['label'].value_counts().to_numpy(),
     labels=df_1['label'].value_counts().index,
    marker=dict(colors=['darkorange','green'])),
    row=1, col=2)

def shaper(row):
    shape = image.load_img(row['path']).size
    row['height'] = shape[1]
    row['width'] = shape[0]
    return row
df_1 = df_1.apply(shaper,axis=1)
df_1.head(5)

train_df, test_df = train_test_split(df_1, test_size=0.2, random_state=42)

# Image Augmentation

generator = ImageDataGenerator(
    rotation_range= 20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range = 2,
    zoom_range=0.2,
    rescale = 1/255,
    validation_split=0.2,
    #horizontal_flip=True,
)

train_gen = generator.flow_from_dataframe(train_df,x_col='path',y_col='label',images_size=(256,256),class_mode='binary',subset='training')
val_gen = generator.flow_from_dataframe(train_df,x_col='path',y_col='label',images_size=(256,256),class_mode='binary',subset='validation')
test_gen = generator.flow_from_dataframe(test_df, x_col='path', y_col='label', target_size=(256, 256), class_mode='binary', subset=None)

class_indices = {}
for key in train_gen.class_indices.keys():
    class_indices[train_gen.class_indices[key]] = key

print(class_indices)

sns.set_style('dark')
pics = 6 #set the number of pics
fig,ax = plt.subplots(int(pics//2),2,figsize=(15,15))
plt.suptitle('Generated images in training set')
ax = ax.ravel()
for i in range((pics//2)*2):
    ax[i].imshow(train_gen[0][0][i])
    ax[i].axes.xaxis.set_visible(False)
    ax[i].axes.yaxis.set_visible(False)

import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPool2D

model = Sequential()
model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=train_gen[0][0][0].shape))
model.add(AveragePooling2D())
model.add(Dropout(0.5))

model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))
model.add(AveragePooling2D())
model.add(Dropout(0.5))

model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
model.add(AveragePooling2D())
model.add(Dropout(0.5))

model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))
model.add(AveragePooling2D())
model.add(Dropout(0.5))

model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))
model.add(AveragePooling2D())
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dense(units=256, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(units=128, activation='relu'))
model.add(Dense(1,activation = 'sigmoid'))
model.summary()

#Custom implementation of focal loss function
def focal_loss(y_true, y_pred, gamma=6.0, alpha=0.25):
    # Binary crossentropy
    bce = tf.keras.backend.binary_crossentropy(y_true, y_pred)

    # Calculate the modulating factor
    p_t = tf.math.exp(-bce)
    focal_loss = alpha * (1 - p_t)**gamma * bce

    return focal_loss

from tensorflow.keras.metrics import Recall,AUC
import time

model.compile(optimizer='adam',loss=focal_loss,metrics=['accuracy',Recall(),AUC()])
# model.compile(loss='sparse_categorical_crossentropy', optimizer= 'adam',metrics=['accuracy',Recall(),AUC()])

start_time = time.time()

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

early_stoppping = EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)
reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=5)
model.fit(x=train_gen,batch_size=32,epochs=15,validation_data=val_gen,callbacks=[early_stoppping,reduce_lr_on_plateau])

end_time = time.time()

training_time = end_time - start_time

print(f"Average training time per epoch: {training_time / 15} seconds")

eval_list = model.evaluate(test_gen,return_dict=True)
for metric in eval_list.keys():
    print(metric+f": {eval_list[metric]:.2f}")

def plot_confusion_matrix(conf_matrix, class_names):
    fig, ax = plt.subplots()
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion Matrix')
    plt.show()

#To Generate A Confusion Matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report
import numpy as np

# Encode true labels to integers
label_encoder = LabelEncoder()
test_df['label'] = label_encoder.fit_transform(test_df['label'])
y_true = test_df['label'].values
y_pred_prob = model.predict(test_gen)

y_pred = (y_pred_prob > 0.5).astype(int)

conf_matrix = confusion_matrix(y_true, y_pred)

class_indices = {v: k for k, v in train_gen.class_indices.items()}

class_names = ['Fire', 'Non-Fire']

# Plot the confusion matrix
plot_confusion_matrix(conf_matrix, class_names)

print("Class Labels:")
for i in range(len(class_indices)):
    print(f"{class_indices[i]}: {i}")

# Print a classification report for more detailed metrics
class_report = classification_report(y_true, y_pred)
print("Classification Report:")
print(class_report)

!curl https://static01.nyt.com/images/2021/02/19/world/19storm-briefing-texas-fire/19storm-briefing-texas-fire-articleLarge.jpg --output predict.jpg

from tensorflow.keras.preprocessing import image
#loading the image
img = image.load_img('image.png')
img

img = image.img_to_array(img)/255
img = tf.image.resize(img,(256,256))
img = tf.expand_dims(img,axis=0)

print("Image Shape",img.shape)

prediction = int(tf.round(model.predict(x=img)).numpy()[0][0])
print("The predicted value is: ",prediction,"and the predicted label is:",class_indices[prediction])

def shaper(row):
    shape = image.load_img(row['path']).size
    row['height'] = shape[1]
    row['width'] = shape[0]
    return row
df_2 = df_1.apply(shaper,axis=1)
df_2.head(5)

generator = ImageDataGenerator(
    rotation_range= 20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range = 2,
    zoom_range=0.2,
    rescale = 1/255,
    validation_split=0.2,
    #horizontal_flip=True,
)

test_df = generator.flow_from_dataframe(df_2, x_col='path', y_col='label', target_size=(256, 256), class_mode='binary', subset=None)

eval_list = model.evaluate(test_gen,return_dict=True)
for metric in eval_list.keys():
    print(metric+f": {eval_list[metric]:.2f}")

# Encode true labels to integers
label_encoder = LabelEncoder()
df_2['label'] = label_encoder.fit_transform(df_2['label'])
y_true = df_2['label'].values
y_pred_prob = model.predict(test_df)

y_pred = (y_pred_prob > 0.5).astype(int)

conf_matrix = confusion_matrix(y_true, y_pred)

class_indices = {v: k for k, v in train_gen.class_indices.items()}

class_names = ['Fire', 'Non-Fire']

# Plot the confusion matrix
plot_confusion_matrix(conf_matrix, class_names)

print("Class Labels:")
for i in range(len(class_indices)):
    print(f"{class_indices[i]}: {i}")

#print a classification report for more detailed metrics
class_report = classification_report(y_true, y_pred)
print("Classification Report:")
print(class_report)